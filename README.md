# Medicare Chat Assistant

A work-in-progress LLM-powered assistant for answering Medicare billing, coverage, and policy questions. The project aims to combine a fine-tuned LLaMA 3â€“8B model with policy retrieval using Retrieval-Augmented Generation (RAG).

    This project is in the initial setup phase. No code or models are functional yet.

ğŸš§ Goals

 - Fine-tune an open-source LLM (starting with LLaMA 3â€“8B) using Medicare billing and provider data
 - Implement a RAG pipeline to retrieve relevant Medicare coverage policies (NCDs/LCDs)
 - Deploy a FastAPI backend for querying the model
 - Optionally build a lightweight UI using Streamlit or Gradio

ğŸ“ Planned Directory Structure
```
medicare-chat-assistant/
â”‚
â”œâ”€â”€ api/ # FastAPI backend for chat interface
â”œâ”€â”€ data/ # Medicare datasets (not committed to Git)
â”œâ”€â”€ models/ # LoRA weights and base models (not committed to Git)
â”œâ”€â”€ rag/ # Document indexing and retrieval (FAISS/ChromaDB)
â”œâ”€â”€ tuning/ # Fine-tuning scripts for LLaMA 3â€“8B using LoRA
â”œâ”€â”€ ui/ # Optional Streamlit or Gradio frontend
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
```

Future Features (Planned)

 - Fine-tune using LoRA with Medicare claims data
 - Embed Medicare policy documents and set up vector search
 - Integrate model and retriever via API
 - Deploy web-based chat interface

 
=======
