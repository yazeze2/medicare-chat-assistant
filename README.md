# Medicare Chat Assistant

A work-in-progress LLM-powered assistant for answering Medicare billing, coverage, and policy questions. The project aims to combine a fine-tuned LLaMA 3â€“8B model with policy retrieval using Retrieval-Augmented Generation (RAG).

    This project is in the initial setup phase. No code or models are functional yet.

ğŸš§ Goals

 - Leverage an open-source LLM (LLaMA 3â€“8B) as the reasoning engine for Medicare questions.
 - Implement a **Retrieval-Augmented Generation (RAG)** pipeline to ground responses in official Medicare documentation (e.g., Medicare & You, NCDs, LCDs).
 - Experiment with **chunking** and **retrieval** strategies (fixed-size, heading-aware, semantic) to optimize recall and precision.
 - Develop a lightweight **evaluation framework** to measure retrieval quality, answer faithfulness, and citation accuracy.
 - Maintain year-specific cost and deductible values via configuration files (amounts_YYYY.yaml) to keep answers current.
 - Deploy a FastAPI backend to expose the assistant as an API for integration and testing.
 - Optionally build a lightweight user interface (Streamlit or Gradio) for demos and interactive exploration.

ğŸ“ Planned Directory Structure
```
medicare-assistant/
â”œâ”€ README.md
â”œâ”€ LICENSE
â”œâ”€ .gitignore
â”œâ”€ requirements.txt                # optional convenience for contributors
â”œâ”€ pyproject.toml                  # installable package metadata (setuptools)
â”œâ”€ src/
â”‚  â””â”€ medicare_assistant/          # importable package
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ version.py
â”‚     â”œâ”€ prompts.py
â”‚     â”œâ”€ amounts.py
â”‚     â”œâ”€ rag/
â”‚     â”‚  â”œâ”€ __init__.py
â”‚     â”‚  â”œâ”€ chunking.py            # placeholder (to implement)
â”‚     â”‚  â”œâ”€ retriever.py           # placeholder (to implement)
â”‚     â”‚  â””â”€ pipeline.py            # placeholder (to implement)
â”‚     â””â”€ ingest/
â”‚        â”œâ”€ __init__.py
â”‚        â””â”€ pdf.py                 # placeholder (to implement)
â”œâ”€ tests/
â”‚  â””â”€ test_imports.py              # starter test
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_baseline_no_rag.ipynb     # model sanity checks (no RAG)
â”‚  â””â”€ 02_development.ipynb         # to explore and use for dev
â”‚  â””â”€ 03_ingest_and_ask.ipynb      # end-to-end demo (ingest â†’ ask)
â”œâ”€ data/
â”‚  â”œâ”€ raw/                         # source PDFs/HTML (ignored in git)
â”‚  â”œâ”€ processed/                   # extracted text (ignored in git)
â”‚  â””â”€ config/
â”‚     â””â”€ amounts_2025.yaml         # year-specific amounts (not packaged)
â”œâ”€ models/                         # local GGUF models for llama.cpp (ignored)
â””â”€ chroma_db/                      # persisted vector store (ignored)

```

Future Features (Planned)

 - Fine-tune using LoRA with Medicare claims data
 - Embed Medicare policy documents and set up vector search
 - Integrate model and retriever via API
 - Deploy web-based chat interface

Data Sources

This project uses official Medicare references curated for retrieval-augmented generation:
- **Medicare & You 2025 Handbook** â€“ high-level beneficiary guide.
- **CMS Manuals (Pubs. 100-02, 100-04)** â€“ detailed benefit and claims processing rules.
- **National Coverage Determinations (NCDs)** â€“ national-level coverage policies.
- **HCPCS Code Set (2025)** â€“ billing and procedure codes.
- **Medicare Cost Reference (YAML)** â€“ structured deductibles, premiums, and coinsurance for 2025.
- **Enrollment Periods Reference (CMS)** â€“ rules for IEP, GEP, SEP, and OEP.
(See [`data/README.md`](data/README.md) for details.) 
=======
